{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classroom 3 - Basic machine learning with ```Pytorch```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing we need to do for this workshops is install both ```pytorch``` and ```scikit-learn```, along with some other packages we need for this week.\n",
    "\n",
    "```\n",
    "pip install --upgrade pip\n",
    "pip install torch sklearn matplotlib pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Load packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system tools\n",
    "import os\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating a tensor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.tensor([[1., -1.], \n",
    "                         [1., -1.]])\n",
    "print(type(x_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.],\n",
      "        [ 1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Tensor to numpy arrray__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "x_array = x_tensor.numpy()\n",
    "print(type(x_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__And back again__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "x_tensor2 = torch.tensor(x_array)\n",
    "print(type(x_tensor2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n"
     ]
    }
   ],
   "source": [
    "# check for identity\n",
    "print(x_tensor2 == x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the minimum of an polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin here by creating an initial value for ```x``` and defining the function ```y```.\n",
    "\n",
    "The goal is to find the _minimum_ value of y, i.e. in this case the turning point of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is just a number, a tensor of rank 0. Requires_grad means track the gradient\n",
    "x = torch.tensor([3.], \n",
    "                 requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2 - 3*x + 2\n",
    "print(y) #Result: \"tensor([2.], grad_fn=<AddBackward0>)\" just means 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create SGD optimizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD stochastic gradient descent \n",
    "optimizer = torch.optim.SGD([x],     # starting value\n",
    "                            lr=0.01) # learning rate i.e. how big steps to take\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calcuate the gradient__\n",
    "\n",
    "We first run a _backwards pass_ which computes the gradient of the function ```y``` for given value ```x```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad) # examine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Make a step in the right direction__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step in the direction to minimize y\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the gradient back to zero. (This is a bit wierd but required). Since the gradient is not actually zero\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5000], requires_grad=True)\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# changed from 3 to 2.97 i.e. we have taken a small step down\n",
    "# we see that x have improved (minimum is 1.5 so moving in the right direction)\n",
    "print(x)\n",
    "# we see that the gradient is set to zero\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run this for 1000 steps__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    #print(x)\n",
    "\n",
    "    # forward pass / or just calculate the outcome\n",
    "    y = x**2 - 3*x + 2\n",
    "\n",
    "    # backward pass on the thing we want to minimize\n",
    "    y.backward()\n",
    "\n",
    "    # take a step in the \"minimize direction\"\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradient\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Print the local minimum__\n",
    "\n",
    "What we see is that using stochastic gradient descent with a defined starting point allows us to correctly calculate the local minimum of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# after 1000 trials, we have found the minimum. It reaches 1.69 after 100 trials\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus task\n",
    "\n",
    "- Try and define some functions of your own and see if you can find the minimum. (There are tools online where you can check what the actual minimum is, to see if the algorithm gets it right!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8333], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([4.], \n",
    "                 requires_grad=True)\n",
    "\n",
    "#SGD stochastic gradient descent \n",
    "optimizer = torch.optim.SGD([x],     # starting value\n",
    "                            lr=0.01) # learning rate i.e. how big steps to take\n",
    "\n",
    "for i in range(1000):\n",
    "    #print(x)\n",
    "\n",
    "    # forward pass / or just calculate the outcome\n",
    "    y = 3*x**2-5*x+2\n",
    "\n",
    "    # backward pass on the thing we want to minimize\n",
    "    y.backward()\n",
    "\n",
    "    # take a step in the \"minimize direction\"\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradient\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same general procedure can be used when performing linear regression on data points. \n",
    "\n",
    "In this example, we're using ```scikit-learn``` to artificially generate some data points for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulating data, random state = seed \n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100,    # number of individual data points\n",
    "                                            n_features=1,     # each data point represents a single feature\n",
    "                                            noise=20,         # technically, SD of gaussian noise applied to the output\n",
    "                                            random_state=4)   # a random state for reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot the data__\n",
    "\n",
    "Note that here we're using ```matplotlib``` the lazy way, instead of explicitly defining ```fig, ax```. This is fine for experimental notebooks, but don't do it in your codebases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the sample\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert data to tensors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to float Tensor\n",
    "X = torch.tensor(X_numpy, dtype=torch.float)\n",
    "y = torch.tensor(y_numpy, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check the shapes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# they dont have the same number of dimensions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reshape ```y```__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "y = y.view(y.shape[0], 1) # view is similar to reshape it simply sets the desired shape to (100, 1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check datatypes__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(y.dtype)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get number of samples and features__\n",
    "\n",
    "We'll use this information below when calculating loss function etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialize a linear model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model f = wx + b\n",
    "input_size = n_features \n",
    "output_size = 1 #1 because every input is gonna predict a single output\n",
    "\n",
    "# create a weight and biases (betas and intercept) initialized 'randomly'\n",
    "model = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set learning rate, check parameters__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.1094]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.2578], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01 # feel free to change this\n",
    "# these are the weights. i.e. the m in \" y = m*x+b \", b is the bias\n",
    "print(list(model.parameters())) # only two parameters a beta and an intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Define a loss function and an optimization algorithm__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the loss function, using mean squared error \"Criterion for estimating how well the model is performing\"\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), # parameters to optimize\n",
    "                            lr=learning_rate    # the speed in which we optimize them  / how fast the model learns (think step size) \n",
    "                            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run for 100 epochs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 4070.3374\n",
      "epoch: 20, loss = 2867.7063\n",
      "epoch: 30, loss = 2048.0488\n",
      "epoch: 40, loss = 1489.2861\n",
      "epoch: 50, loss = 1108.2950\n",
      "epoch: 60, loss = 848.4628\n",
      "epoch: 70, loss = 671.2238\n",
      "epoch: 80, loss = 550.2995\n",
      "epoch: 90, loss = 467.7810\n",
      "epoch: 100, loss = 411.4597\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass / calc predicted y\n",
    "    # a + b*X\n",
    "    y_predicted = model(X)\n",
    "    \n",
    "    # calucate loss / MSE\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    # Backward pass / gradient and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # some print to see that it is running\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get predicted values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "predicted = model(X).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Plot results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f295a0f3b50>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhCUlEQVR4nO3dfZBc1Xkm8OeZQSKMMIUZTUAIZkaAoBZIzFpTxKw3FBh7EcqHjGuNSY2ANWZVxuCyY1IsRJus48rErA2mSGFwZIMta2ZNsL0GJRAEcnkhqRibkcH6AGMk0AgJWRpJjgMIkDTz7h/ntuZ233u7b3ffj+6+z6+qa6ZPd98+U4i3T7/nnPfQzCAiIsXSlXcHREQkewr+IiIFpOAvIlJACv4iIgWk4C8iUkBH5d2BuObOnWuDg4N5d0NEpG2sX79+r5n1hT3WNsF/cHAQ4+PjeXdDRKRtkJyIekxpHxGRAlLwFxEpIAV/EZECUvAXESkgBX8RkQJS8BcRScPYGDA4CHR1uZ9jY3n3qEzbLPUUEWkbY2PA8uXAgQPu/sSEuw8Aw8P59ctHI38RkaStWDET+EsOHHDtLULBX0Qkadu319ceJuW0kYK/iEjS+vvra69UShtNTABmM2mjBD8AFPxFRJI2MgL09JS39fS49jgySBsp+IuIJG14GFi5EhgYAEj3c+XK+JO9SaSNalDwFxGJo94c/PAwsG0bMD3tftazyqfZtFEMCv4iIrVkkIMv02zaKAYFfxGRWqJy8Ndck85qnGbTRjHQzBK7WJqGhoZM9fxFJBddXW7EX01PT+IBulkk15vZUNhjGvmLiNQSJ9feYpu4alHwFxGpJSwHHybB1TgA8PLLbnohDartIyJSSymVs2KFC/BdXcDUVPB5Ca3G2bcPmD8feOcdYM4c4I03ErlsGY38RUTi8C/dXLUqldU4U1PApZcCc+e6wA8Aa9Y0dclIiQR/kveT3ENyk6/t8yR3knzOuy3xPXYryS0kXyR5aRJ9EBHJTAqrcUZGgKOOAh5/3N3/4hfdHPMHPpBQnysklfb5FoC7AXy7ov1OM7vd30DybABXAjgHwMkA1pE808xCvkOJiLSo4eFEVvasXQssXjxz/7LLgH/4B6C7u+lLV5XIyN/MngKwP+bTlwJ4wMzeMbNXAGwBcH4S/RARSVxK1TVfftl9aSgF/mOOAfbuBR59NP3AD6Sf87+R5AYvLfRur20+gFd9z9nhtQWQXE5ynOT45ORkyl0VEamQws7eAweAM84ATj99pu3ZZ117b28CfY4pzeB/L4DTAZwHYBeAO+q9gJmtNLMhMxvq6+tLuHsiIjUkWF3TDLjuOrd6Z+tW1zY66trPO6/5rtYrteBvZrvNbMrMpgF8HTOpnZ0ATvU99RSvTUSktizPxk2ouuY3v+m6e9997v4NN7hFQ3luBk4t+JOc57t7OYDSSqA1AK4keTTJBQAWAvhpWv0QkQ6SdYG1Jqtrfv3rLq9/7bXu/jnnuC8Od9/t2vOU1FLP7wD4MYCzSO4g+QkAXyK5keQGABcD+FMAMLPNAB4E8DyAxwDcoJU+IhJL3DRMUt8OGqyu+fzzLriXzmwH3BaBTZvcxG4rUGE3EWkfUQXWSJdHAWa+Hfg/JJopujY2NrOzt7/fBf6I67z9djC433or8Dd/U//bJqFaYTcFfxFpH4OD4cVuBgbc0Druc1JQ+bk0dy6Q9yJFVfUUkc4QJw2TwRGIfjfe6L54+AP/wYP5B/5aFPxFpH3EKauQwRGIwMyk7Ve/OtO2dav7EJg1K9G3SoWCv4i0l1pn46Z8BGJpZ+6nPz3TVlqvf9ppibxFJlTSWUQ6S2X55RqTtHFNT4eXXWiTadMABX8R6TwJFV0rCVuTPz2d/1r9ZijtIyISgQwG+Ndec6P9dg78gIK/iEjAnXcGg/vIiAv68+aFv6bdKO0jIuLZvRs46aRge7vm9avRyF9E8pdlsbYIZDDwm3Vm4Ac08heRvFWWYygVawMyKXsZlrs/cKB1avCkRSN/EclXgjXz63HxxcHA//DDbqTf6YEf0MhfRPKWcTmGJ58ELrqovO2ss4Bf/CKVt2tZCv4ikq/+/vBCbAmXYzh8OLzsQqfm9GtR2kdE8pVyOQbApXcqA38nT+bGoeAvIvmKU6ytQWGbtF55pdhBv0TBX0TyV6tYW50+/elg0L/1Vhf0BwebunTHUM5fRNqfd9rWtgliAV4JPKyRfpBG/iJF0wIbqhLl7RPgxLZA4C96Xr+apA5wv5/kHpKbfG0nkHyC5Evez3d77ST5tyS3kNxA8r1J9EFEYihtqJqYcFGxtKGqjT8AuGwYPPBmWdtb+C3YwGA+HWoTSY38vwVgcUXbLQB+aGYLAfzQuw8AlwFY6N2WA7g3oT6ISC05bahKQ9hk7jfwCRiI38I7qe0T6BSJBH8zewrA/ormpQBWeb+vAvBhX/u3zXkawPEkO6ROnkiLy3hDVRruuiu8JIOB+ATun2lIeJ9Ap0kz53+ime3yfv8VgBO93+cDeNX3vB1eWwDJ5STHSY5PtvppyCLtIKPzbdNw4IAL+p/9bHm7jY7BeuaUNya8T6ATZTLha2YGoO5pFzNbaWZDZjbU19eXQs9ECiaDDVVpIIE5FfH9yGRuivsEOlmawX93KZ3j/dzjte8EcKrvead4bSKStiwDZQKrisLy+hs3hqzgSXifQBGkGfzXALjG+/0aAA/72q/2Vv28D8BvfOkhEUlbFoGyyVVF554bDPoXXOAude65yXe3iGgJLIIl+R0AFwGYC2A3gP8F4CEADwLoBzAB4Aoz20+SAO6GWx10AMDHzWy81nsMDQ3Z+HjNp4lIKxgcDC/WNjDgPnAi/OxnwKJFwXat1W8MyfVmNhT2WCI7fM3sTyIeuiTkuQbghiTeV0RaVNTqoYkJ98GwfbubZB4ZOfLNI3QFj4J+arTDV0SSF7V6iAykgsLy+m+/rcCfNgV/EUle2KoisiyiExbYmXvHHe4pRx+dRSeLTcFfRMI1s1onbFWRF/hvxv8GQ1Z+mwGf+1wyXZfaVNVTRIKSOFR9eLjsub8+9Xdxwo4NgafZwGDVSWBJh0b+IhKUcA0gEoHAb6DbmdviG8w6lYK/iAQlVAMobDL35/MWw9ilnbg5U9pHRIKaPFQ9bNnmyScDO3cCwGNNdU2SoZG/SBHVmsxtsAbQww9Hr9ffqSIuLUUjf5GiiTOZW/q5YkXohqxKZu5zJKxdWpNG/iKdKmp0H3cyN2YNIDIY+N95R4G/1Sn4i7SLetbdVyusVq30Qh1r+cMmc7/wBfd2s2fHvozkRMFfpB3UWyWz2ui+2qRt5TVDPnAWL47O6//FX9T7h0leFPxF2kG96+6rLdVcsiT6ffzXrPjA2T3xFrhsGGvXlr/kyKEqJQnU8Zf0JVLSOQsq6SyF1tUVnkQnXU6+UlRJ5e5u4PjjgX37ot+rdE3fNaLKMQRUTiYDbpWQ1vPnolpJZ438RdpBvWfvhi3VBICpqeqBHwBOOMH93L7dFV+rCPybcU70ZG7CO4MlPQr+Iu2g3nX3pcJq3d0NvR0J0Mq/Ufw2dsNAnD3wZsSrkNjOYEmfgr9IO2jk7N3h4fCUUBV34HPgvr2BdgOxGyfV3uhV7zcUyY02eYm0i4oqmbFElWmoYAC6wvL6vXPdL/tZc6MXAPd4WM5fxdtaTuojf5LbSG4k+RzJca/tBJJPkHzJ+/nutPsh0tLSWiETdaiK/y4sEPgP4SgY6OYH3noLWL063mHvjXxDkVxklfa52MzO88063wLgh2a2EMAPvfsixVTvGv56VDlUJWwyd/nRq2AgjsLUTGO9E7YxdwZLvvLK+S8FsMr7fRWAD+fUD5H8NbtCpta3hopgHBb0AXeoyt8d/Hj4e2jCtuNkEfwNwOMk15P0qkfhRDPb5f3+KwAnhr2Q5HKS4yTHJycnM+iqSA6aWSFTx7eG9esjdub6D1XRhG1hZBH8/7OZvRfAZQBuIHmh/0Fzu8xCVw2b2UozGzKzob6+vgy6KpKDZgJuzG8NJDBUsdXHBgaDh6o0WMpZ2k/qwd/Mdno/9wD4AYDzAewmOQ8AvJ970u6HSKZqpWL8j7/xBjBrVvnjcQNujW8NYcXX/vmfvbR/WF5eE7aFkWp5B5JzAHSZ2eve708A+AKASwDsM7PbSN4C4AQzu7natVTeQdpGrRIHYY/Png28613A/v3xllSWRJRxCMvpAyqzXDR5lnc4EcC/kPw5gJ8CeMTMHgNwG4APkXwJwAe9+yKdoVYqJuzxgweBY48tH4lHfXuo8q1hCR6JrMOjwC9+KuwmkrRaRdjiFGmL+vZwzTXAqlWBD4/DnIVZdjBwyTb531tSosJuIlmqNYEb9bjZzAg/6tvDypWBdsICgf9w/2mwUZVSlmgK/iJhmtlxW2vFTFTFTWBmqWZUSYapmc1XYev1P4wfwEB0b3+l/o1iqsNfLGbWFrdFixaZSCZGR816ekppcnfr6XHt9VxjYMCMdD8rX1t63P8e/lt3d3g7GfmS0MaBgez+Zmk5AMYtIqYq5y9SKeoglIEBNxmbpKj8P+C+HfhSPI90/zH+cOrhwNMMITu3SqIOe6mU5d8smVHOX6QeWdakj8r/l9bXe+vtCQsEfvMSPw1dv5Lq8BeOgr9IpaRKHFTm0D/1qWBOvdr8wPAwOLEtcKjKv+KCYNDv7XV7BcKuE4fKOhSOgr9IpSRKHITV3Ln33mANHiB0Ry2XDUfW4bkATwcfuOsu4P77G9+Zq7IOxRM1GdBqN034SqZqTdjWUm0yt8qE7Ny5EZO5Zma9vdHXSWJyttm/WVoONOErkrFqE7l+3oTs228DxxwTfNgGBl3evb8fWLIE+MY3gEOHwq+lyVmpoAlfkazFzZX394MMBv7pE+a6vL4/TbRqFXDdddHX0uSs1EHBX6QRtTZEVdvI5SEMnNhW1rZ00auwnjng/n3BFxw4ADz6qBvhh9HkrNRBwV+kXnEOUAkrjXz99cDAQPRJWgY8tPf3g2Ud/LZv1+SsJEI5f5F6NbghamwMWLYs2F72v2CtuYLSe5Tq/5TmA+KWgJZCUc5fpJp6a9pE5daj6vHADf4rA39pqU6Zaqkb/+heh6RLkxT8pdjqOAP3iGoBuuJ1YSdpbbrtH8uDfmV9/srNWoDbxKUTtSRBCv5SbDHPwC1TLbf+mc8ACA/6gNukdc4XPlZ+MIv/w2ffPvezt3dmrmB0FNi7V4FfEqWcvxRbnINVwoRFdlQ5PrGyHEMpd6+CapIi5fxFojRS0yYkJfQbHBe+gieq+Fpp3kAF1SQnCv5SbI0sm6xICRGG4/GbsjYzb3dulP5+9yHSFfG/oNbsS8pyC/4kF5N8keQWkrfk1Q8puLD1+LUmVr1Redh6/St+b2Imi1Rt9L5kicv1+07mOkJr9iUDR+XxpiS7AXwVwIcA7ADwDMk1ZvZ8Hv2RAhsbc5O0+7wdtW+8UfMllSWWS2zOscDTvtf394fn83t73U7dsM1c3d1a1SOZyGvkfz6ALWb2spkdBPAAgKU59UWKamwMuPbamcAPuN8//vHyvL63FPPLvDlyBY+BwJtvupr9JVEppbvuqn5GrwK/ZCCv4D8fwKu++zu8tjIkl5McJzk+OTmZWeekIFasAA4eDLYfOjST1/eWYnJiG27Gl8qeFjqZe++9Mx8c1VJK3d3R/dLh6ZKBXJZ6kvyvABab2XXe/asA/J6Z3Rj1Gi31lMRVK6XgLfUMG+m/hDNwBrZGXzfOMs2IpaJH9PQo/SNNa8WlnjsBnOq7f4rXJpKdKitqaOGB38DqgR+It0wzqjJnSa2NZiJNyiv4PwNgIckFJGcDuBLAmpz6IkU1MhIopRBZcTPOYeklcZZpxij5rLX+kqZcgr+ZHQZwI4C1AF4A8KCZbc6jL1IglQXcAHfubW8vduO3w4P+6BisZ05546xZ1d8nzjJN/3xAFK31lxTlts7fzB41szPN7HQz06JmSVdUATcA3LcXJ2F32dOPVNwMm7T95jddvZ2wD4Hrr4+fpy9V5hwdVX1+yZx2+EpnqFWWOaSAGw+8CS4rD9Q33RQyB1wK0qtXu/tXXeWud9115R8Ko6PAPffU3/dGNpqJNCvqZPdWuy1atKjJc+ylY42OmvX0lAbr7tbT49pLyCOP+Z/mvzX9HpXPHxhw7zswEP08kRQBGLeImKqRv7S/OGWZ+/vx5xiJPD6x5orneko/N3JGgEjGFPyl9dVK6cSojMmJbfgi/rzsYeuZAxuNGZDrqb7ZyBkBIhlT8JfWFjaKXrYMmDt35kMgalVMV1fooSqv4WRXcTMsrx71QVNP6WeVaZY2oMNcpLVFHXYCzOyCBdwHhG+0HXmoSrV/7qUPGv+ovcp7RO7C1QEt0iJacYevSDzVRsulVIpvtUzVTVrV6usD1dM19azIaeSMAJGMaeQvra3ayB84UoNn2zZgwYLgw6HHJ46MhAftRo90DDM25j40tm93qaGo9xRJkUb+0n5KufeJiepF0Pr7QQYDf2Q5hmorbxo50jFKaW/A9LT7qcAvLUbBX5pXazVOI9crTfICkYl6wsCJbWVtIyOuJEPVujlRK2+UrpECyeUkL+kglZOkvrIJDY92w3LvgDsB69hjAwG/ZOYzYnjmOlEpo7C5hGHf65SukQ6nnL80J42VLRG595twB76CzwXaq/4T1sobKTDl/CU9aaxpD8mxExYI/KE7cytTUEuWKJUjEkLBX5qT5CRpiS/3HrZ089/+LWK0H7YhbNUq4JprVDRNpILSPtKcahujmgiwUQt8lOIRiU9pH0lPPZufYqwKCivHAFSkeKKuo7IKIrEp+Eu5RpZtxlnTXqPS5datMYJ+reukkYIS6VBK+8iMlFI4AKqmZMKWbkb+s6yW2hkZSa//Im0ol7QPyc+T3EnyOe+2xPfYrSS3kHyR5KVp9UHqlGYp4pDUS9gmre99r0Zev1pqRydiicSW9iavO83sdn8DybMBXAngHAAnA1hH8kwzm0q5L1JLmjnz/v4jI/aGKm6GXCfQDrhAr2AvUlMeOf+lAB4ws3fM7BUAWwCcn0M/pFKaOfOREfzPo25r/CQt33W0bl+keWkH/xtJbiB5P8l3e23zAbzqe84Ory2A5HKS4yTHJycnU+6qpBVYzQAuG8bI4f9R3j46Fj/olyi1I5KIpoI/yXUkN4XclgK4F8DpAM4DsAvAHfVe38xWmtmQmQ319fU101WJI4XASrqFQ35vv+2N9OOeohXWT1XMFGlKJqt9SA4C+EczO5fkrQBgZl/0HlsL4PNm9uNq19Bqn/YStmzzkkuAdesiXhC20oh0nxLVavCLSKRqq31Sm/AlOc/Mdnl3Lwewyft9DYD/Q/IrcBO+CwH8NK1+SLYa2pkLhK80Kr0oiUqhIlImzZz/l0huJLkBwMUA/hQAzGwzgAcBPA/gMQA3aKVP+3vhhZibtKJUO60LSG7JqYgASHHkb2ZXVXlsBICWZ3SIqKBfl+5uYKrGGEBlGkQSo/IO0rCwOjxPPtlA4AdqB35AZRpEEqTgL3WLLL42OoYLrx6MVxeocmVPb2/1N9VafpFEKfhLbCMjVfL6o9ULt5UJK872+uvArFnlzyu9mdbyiyROhd2kpulpl5KvVPZPp55a+lHP9c7o1fm5IsnIZamntLmxMWDFitCKm4cOAUdV/suppy5Q1HP37wf27q2rmyLSGKV9JGhsDFw2HAj8N71nHcxCAj9QX10g1d0XyZ2Cv5S5+mpXh6eSgbh9w3+ZyeE3c1C6irOJ5E7Bv5PVcSrXrl1ufnX16vJ2845Qd3fMbbRq9qB0FWcTyZ0mfDtVHadyha7gQUSdBjK6pr4OShdpKTrAvYhinMoVtl7/tde8ZZtRRXr6+3VQukgHUPDvVFUC9OzZwdh+000ugzNvHtw3g09+Mvja2bNdXl4TtiJtT8G/U4UE4kdxGWjTOHSovN0MuP32iie///3BTVelFKEmbEXanoJ/p/IF6GkQhOEP8GjZU6pW3FyxAoFPiUOHXLsmbEXaniZ8O5m3Xr/S9HR0Sv+Irq7wTwbSXUBEWp4mfAuIDK7X/9GPvPN0awV+IJ+8fh1LU0WkOQr+Heav/zoY3E87zQX9iy6q40JZ5/XD9g5EFYYTkaYp7dMh9uwBTjwx2F73f16vpg+2bwdOOMG17d+ffqG1egrDiUgsKuzW4RI5SQsIbgzbt8+N9levTn8yV3sHRDKltE8bC9uk9RscB+uZ01i6JMbGsNRo74BIppoK/iQ/SnIzyWmSQxWP3UpyC8kXSV7qa1/stW0heUsz719US5cGg/7f4woYiOPweuMBu57Rd9KTs9o7IJItM2v4BuA/ADgLwP8DMORrPxvAzwEcDWABgK0Aur3bVgCnAZjtPefsOO+1aNEiK7qNG0sr82du87Az2AiYkfEuOjpqNjDgnt/VFX6t3t6Z5wwMmF1/vVlPT/lzenrctZrh78vAQPPXEyk4AOMWEVObGvmb2Qtm9mLIQ0sBPGBm75jZKwC2ADjfu20xs5fN7CCAB7znShXTq8dAAr/zO+XtZsBrA/8p/EVx0iWVK2zC1u93dbkjFv2rcL72tXTSQ8PDbnJ3etr91KYxkdSklfOfD+BV3/0dXltUeyiSy0mOkxyfnJxMpaOtjgS6ry4PgtPHzHHF14Dm0iVhOf4wBw+W34+aTZ6Y0NJMkTZRM/iTXEdyU8gt9RG7ma00syEzG+rr60v77VrKVVcF8/oT6IeB4Fu+UXYzpRbirKSpdzev1uaLtIWaSz3N7IMNXHcngFN990/x2lClXQCsWwd86EPlbX+PK3AFvlve6A/cw8ONpUii6vL7dXcDU1PBdjL8G0Ap/aOUjUhLSyvtswbAlSSPJrkAwEIAPwXwDICFJBeQnA3gSu+5hff66y6e+gP/hRcCNjAYDPxAMksgw1JGfj09biQfllYKK/lcorX5Ii2v2aWel5PcAeACAI+QXAsAZrYZwIMAngfwGIAbzGzKzA4DuBHAWgAvAHjQe26hkcBxx5W3mQFPPol0l0BWpox6e93Nnz66557wtNI997jfw2htvkjLU3mHHM2bB/zqV+VtBw8Gy+iXlVxIu8xCPeo4KlJEsqeqni3mzjvdINof+J97zo32A4EfaN0lkKrrL9K2VNsnQy+9BJx5ZnnbX/4l8Fd/lU9/EtHoZLOI5ErBPwPT027RTKU2ybiJSAdS2idl73lPMPBXPT6xGh12IiIJUfBPyR13uDT4hg0zbZOTTYz2ddiJiCRIwT9hzz7rgv6f/dlM209+4uL13LlNXDjPcssi0nEU/BPy5psu6L/3vTNtIyMu6J9/fgJv0MhhJ0oTiUgETfgmoLIGzxlnuJU9iYoqxRC1oapyDX4pTQRodY6IaOTfjKuvDgb+w4dTCPxA/Tt9lSYSkSoU/Bvw0EMu6K9ePdP26qsuxRO2pDMR9W6o0pm4IlKF0j512LEDOPXU8rbvfx/4yEcy6kA9G6rqTROJSKFo5B/D1JQbbPsD//CwG+lnFvjrpTNxRaQKjfxrOOss4Je/LG9ri525pW8IrVgQTkRyp5F/hNtuc6N9f+B/4402CfwlrVoQTkRyp5F/hWeeCa7LX7++fP2+iEi708jfUzpJyx/4v/xlN9JX4BeRTqORP4Jr9c89F9i4MZ++iIhkodAj/499LBj4p6YU+EWk8zV7hu9HSW4mOU1yyNc+SPItks95t6/5HltEciPJLST/lqwMv+n77ndd0H/wwZm2nTtdiqer0B+HIlIUzYa6TQA+AuCpkMe2mtl53u2TvvZ7Afx3AAu92+Im+xDbxIQL+ldcMdO2Zo0L+iefnFUvRETy11TwN7MXzOzFuM8nOQ/AcWb2tLmT478N4MPN9CGO0iatwcGZtmuvdUH/j/4o7XcXEWk9aSY5FpB8luSTJH/fa5sPYIfvOTu8ttTcdx9wVMW0tplrFxEpqpqrfUiuA3BSyEMrzOzhiJftAtBvZvtILgLwEMlz6u0cyeUAlgNAf4M1aa67bub3AweAY45p6DIiIh2l5sjfzD5oZueG3KICP8zsHTPb5/2+HsBWAGcC2AngFN9TT/Haoq6z0syGzGyor68v7t9UZs8e4Ne/dqP93AK/DlURkRaTStqHZB/Jbu/30+Amdl82s10A/p3k+7xVPlcDiPwQSULf42M4/rzB/AKvzt4VkRbU7FLPy0nuAHABgEdIrvUeuhDABpLPAfgegE+a2X7vsU8B+AaALXDfCP6pmT5U1QqBV4eqiEgLorVJpbKhoSEbHx+v70WDg+E17QcGXKGzLHR1hVeDI13BNRGRlJBcb2ZDYY919pamVjjNKmqiWoeqiEiOOjv4t0Lg1aEqItKCOjv4t0LgrffsXRGRDHR2Vc9WOc2qnrN3RUQy0NnBH1DgFREJ0dlpHxERCaXgLyJSQAr+IiIFpOAvIlJAnR38VVBNRCRU5672KdX1KdXVKdX1AbT6R0QKr3NH/iqoJiISqXODfyvU9RERaVGdG/xboa6PiEiL6tzg3wp1fUREWlTnBn8VVBMRidS5q30A1fUREYnQuSN/ERGJpOAvIlJACv4iIgWk4C8iUkAK/iIiBUQzy7sPsZCcBDCRdz8izAWwN+9O5KCofzegv72If3s7/t0DZtYX9kDbBP9WRnLczIby7kfWivp3A/rbi/i3d9rfrbSPiEgBKfiLiBSQgn8yVubdgZwU9e8G9LcXUUf93cr5i4gUkEb+IiIFpOAvIlJACv4JIPllkr8guYHkD0gen3efskLyoyQ3k5wm2THL4KKQXEzyRZJbSN6Sd3+yRPJ+kntIbsq7L1kieSrJH5F83vu3/pm8+5QEBf9kPAHgXDP7XQC/BHBrzv3J0iYAHwHwVN4dSRvJbgBfBXAZgLMB/AnJs/PtVaa+BWBx3p3IwWEAN5nZ2QDeB+CGTvjvruCfADN73MwOe3efBnBKnv3Jkpm9YGYv5t2PjJwPYIuZvWxmBwE8AGBpzn3KjJk9BWB/3v3ImpntMrOfeb+/DuAFAPPz7VXzFPyTdy2Af8q7E5KK+QBe9d3fgQ4IAhIfyUEA/xHAT3LuStM6+ySvBJFcB+CkkIdWmNnD3nNWwH1FHMuyb2mL87eLdDqSxwL4PoDPmtm/592fZin4x2RmH6z2OMn/BuAPAVxiHbZ5otbfXiA7AZzqu3+K1yYdjuQsuMA/Zmb/N+/+JEFpnwSQXAzgZgB/bGYH8u6PpOYZAAtJLiA5G8CVANbk3CdJGUkCuA/AC2b2lbz7kxQF/2TcDeBdAJ4g+RzJr+XdoayQvJzkDgAXAHiE5Nq8+5QWb1L/RgBr4Sb9HjSzzfn2KjskvwPgxwDOIrmD5Cfy7lNG3g/gKgAf8P7/fo7kkrw71SyVdxARKSCN/EVECkjBX0SkgBT8RUQKSMFfRKSAFPxFRApIwV9EpIAU/EVECuj/A/VAPcR5p4QAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier with text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we haven't actually looked at any text data! \n",
    "\n",
    "In the following section, we're going to use some real world text data in a binary classification problem. We're going to use document vectorization techniques we saw in the lecutre, and see how to build a Logistic Regression classifier with ```pytorch```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "join() missing 1 required positional argument: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/work/NLP-AU/nbs/classroom_03.ipynb Cell 62'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-153538-0.cloud.sdu.dk/work/NLP-AU/nbs/classroom_03.ipynb#ch0000061vscode-remote?line=0'>1</a>\u001b[0m filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin()\n",
      "\u001b[0;31mTypeError\u001b[0m: join() missing 1 required positional argument: 'a'"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating train/test splits__\n",
    "\n",
    "A common practice when building ML/DL models is to use explicitly defined subsets of data for different tasks - [training vs testing](https://upload.wikimedia.org/wikipedia/commons/b/bb/ML_dataset_training_validation_test_sets.png), for example. This is slightly different from how we work when doing statistical modelling (in most cases).\n",
    "\n",
    "```scikit-learn``` has a simple tool that allows us to quickly split our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"label\"], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating a document vectorizer__\n",
    "\n",
    "There are a lot of different parameters here that we're not going to look at but please do [check them out in the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html).\n",
    "\n",
    "The exact same approach can be applied using TfidfVectorizer() instead of CountVectorizer() - [give it a try](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialize vectorizer__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Fit to the training data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized training data\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "\n",
    "# vectorized test data\n",
    "X_test_vect = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert to tensors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized training data\n",
    "X_train_vect = torch.tensor(X_train_vect.toarray(), dtype=torch.float)\n",
    "\n",
    "# vectorized test data\n",
    "X_test_vect = torch.tensor(X_test_vect.toarray(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convert labels__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training labels\n",
    "y_train = torch.tensor(list(y_train), dtype=torch.float)\n",
    "# test labels\n",
    "y_test = torch.tensor(list(y_test), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Initialization parameters for Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train_vect.shape\n",
    "input_size = n_features \n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creating the model__\n",
    "\n",
    "Notice here that we are still using a Linear layer, but this time we have a different loss function - [Binary Cross Entropy loss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a weight and biases (betas and intercept) initialized 'randomly'\n",
    "model = nn.Linear(input_size, output_size)\n",
    "learning_rate = 0.01 # feel free to change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), # parameters to optimize\n",
    "                            lr=learning_rate    # the speed in which we optimize them  / how fast the model learns (think step size) \n",
    "                            ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run the model for 100 epochs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass / calc predicted y\n",
    "    # a + b*X\n",
    "    m = nn.Sigmoid()\n",
    "    y_predicted = model(X_train_vect)\n",
    "\n",
    "    # calucate loss / MSE\n",
    "    loss = criterion(m(y_predicted.round()), y_train)\n",
    "\n",
    "    \n",
    "    # Backward pass / gradient and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # some print to see that it is running\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Check performance against test data__\n",
    "\n",
    "We need to explicitly use ```torch.no_grad()``` here to make sure that we freeze the gradients and don't accidently update them during inferencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred=model(X_test_vect)\n",
    "    y_pred_class=y_pred.round()\n",
    "    correct = sum(y_pred_class==y_test)\n",
    "    print((correct/X_test.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus tasks\n",
    "\n",
    "- Can you write your own version of ```CountVectorizer()```? In other words, a function that takes a corpus of documents and creates a bag-of-words representation for every document?\n",
    "- What about ```TfidfVectorizer()```? Make sure to look over the formulae in the slides from Wednesday, and also the Jurafsky and Martin book."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.9.2"
=======
   "version": "3.9.12"
>>>>>>> cb6dc939091e89c66aa15671db14553b1afc38d1
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
